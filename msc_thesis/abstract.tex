Deep Reinforcement Learning (DRL) methods on mechanical control are successful on many environments and used instead of traditional optimal and adaptive control methods on some complex cases. However, DRL algorithms does still have challenges. One is control on partially observable environments. When an agent is not informed well about the environment, it must recover information from past observations. In this thesis, DRL control of Bipedal Walker (OpenAI GYM) environment is studied by DRL by continious actor-critic algorithm Twin Delayed Deep Determinstic Policy Gradient (TD3). Since environment is partially observable, several neural architectures are implemented First one is feed-forward neural network under the observable environment assumption, while second and third ones are Long Short Term Memory (LSTM) and Transformer using last 16 time step observation as input to recover hidden state, because environment is assumed to be partially observable.






