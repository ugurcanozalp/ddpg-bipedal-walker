\section{Related Work}
\label{sec:related_work}

Reinforcement Learning methods are used in many mechanical control tasks 
such as autonomus driving \cite{pan_virtual_2017, shalev-shwartz_safe_2016, sallab_deep_2017, wang_deep_2019} 
and autonomus flight \cite{kopsa_reinforcement_2018, abbeel_application_2006, santos_experimental_2012}.

Rastogi \cite{rastogi_deep_2017} used Deep Deterministic Policy Gradient (DDPG) algorithm to walk 
their physical bipedal walker robot along with simulation environment. 
They concluded that DDPG is infeasible to control walker robot 
since it requires long time for convergence. 
Kumar et al. \cite{kumar_bipedal_2018} also used DDPG to perform 
robot walking in 2D simulation environment. 
Their agent converged in approximately 25,000 episodes. 
Song et al. \cite{song_recurrent_2018} pointed out the partial observability problem of bipedal walker, 
using Recurrent Deep Deterministic Policy Gradient (RDDPG)~\cite{heess_memory-based_2015} algorithm 
and acquired better results than original Deep Deterministic Policy Gradient (DDPG) algorithm. 

Fris \cite{fris_landing_2020} used Twin Delayed Deep Deterministic Policy Gradient (TD3) 
using LSTM for their quadrocopter landing task. 
Fu et al. \cite{fu_when_2020} used vanilla RNN with attention mechanism 
using TD3 for car driving task, but not explicit Transformer. 
They reported that their method outperformed 7 baselines. 
Upadhyay et al. \cite{upadhyay_transformer_2019} used all of feed forward network, 
LSTM an original Transformer architectures for balancing pole 
on a cart from Cartpole environment of Gym, and Transformer yield worst results among three architectures.

%%% SAC?