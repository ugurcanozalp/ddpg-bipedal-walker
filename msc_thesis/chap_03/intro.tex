\chapter{NEURAL NETWORKS AND DEEP LEARNING}
\label{chap:dnns}

Through increasing computing power, deep neural networks dominated machine learning since much more data can be handled in this way. 
As a subfield of machine learning, the term deep learning emerged from the idea of machine learning using deep neural networks. 
The recent success in computer vision, natural language processing, 
reinforcement learning etc. was possible thanks to deep neural networks. 

Despite tons of variants, a neural network is defined as a parametrized function approximator inspried by biological neurons. 
The first models of neural network developed by a neurophysiologist Warren McCulloch and a mathematician Walter Pitts in 1943~\cite{mcculloch_logical_1943}. 
However, the idea of neural network known today arised after development of a simple binary classifier called perceptron invented by Rosenblatt et al.~\cite{rosenblatt_perceptron_1958}. 
Perceptron is a learning framework inspired by human brain. Although there are many types of neural networks, 
they are commonly based on linear transformations and nonlinear activations.

Neural networks can approximate any nonlinear function if they are designed as complex as required. 
In deep learning, parameters are updated by backpropagation algorithm to minimize the loss predefined by designer, while loss function depends on output of the network.
