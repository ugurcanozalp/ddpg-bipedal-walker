\section{Building Units}
\label{sec:building_units}

\subsection{Perceptron}
Perceptron is a binary classifier model. In order to allocate input $x$ into a class, feature vector $\phi(x) \in \mathbb{R}^{1 \times d_k}$ is generated by a fixed nonlinear function. Then, a linear model is generated with linear transformation weights $W \in \mathbb{R}^{d_k \times 1} $ in the following form \ref{eqn:perceptron1}.

\begin{equation}
\label{eqn:perceptron1}
y = f(\phi(x) W)
\end{equation}

where $f$ is called activation function. For perceptron, it is defined as step function \ref{eqn:stepfun} while other functions like sigmoid, tanh can also be defined.

\begin{equation}
\label{eqn:stepfun}
f(a) = 
\begin{cases}
1,   & \text{if } a\geq 0\\
0,   & \text{otherwise}
\end{cases} 
\end{equation}

A learning algorithm of a perceptron aims determining the parameter vector $W$. It is best motivated by error minimization of data samples once a cost function is constructed. 

\subsection{Activation Functions}
As in \eqref{eqn:stepfun}, step function is used in perceptron. However, any other nonlinear function can be used instead. This nonlinearity allows a model to capture nonlinearity in data. There are tons of activation function in use today. Commonly used activations are sigmoid, hyperbolic tangent, rectified linear unit, gaussian error linear units.