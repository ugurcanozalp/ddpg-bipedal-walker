\relax 
\providecommand\hyper@newdestlabel[2]{}
\@nameuse{bbl@beforestart}
\catcode `:\active 
\catcode `!\active 
\catcode `=\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {leads}{\numberline {}ABSTRACT}{vii}{chapter*.1}\protected@file@percent }
\babel@aux{english}{}
\babel@aux{turkish}{}
\@writefile{toc}{\contentsline {leads}{\numberline {}\"OZ}{ix}{chapter*.2}\protected@file@percent }
\babel@aux{english}{}
\@writefile{toc}{\contentsline {leads}{\numberline {}ACKNOWLEDGMENTS}{xi}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {leads}{\numberline {}TABLE OF CONTENTS}{xiii}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {leads}{\numberline {}LIST OF TABLES}{xvii}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {leads}{\numberline {}LIST OF FIGURES}{xviii}{chapter*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {leads}{\numberline {}LIST OF ALGORITHMS}{xix}{chapter*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {leads}{\numberline {}LIST OF ABBREVIATIONS}{xx}{chapter*.8}\protected@file@percent }
\@writefile{toc}{\numberline {}CHAPTERS}
\babel@aux{turkish}{}
\babel@aux{english}{}
\babel@aux{english}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}\MakeUppercase  {INTRODUCTION}}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{chap:intro}{{1}{1}{INTRODUCTION}{chapter.1}{}}
\citation{noauthor_bipedalwalker-v2_2021}
\citation{noauthor_bipedalwalkerhardcore-v2_2021}
\citation{brockman_openai_2016}
\citation{brockman_openai_2016}
\citation{noauthor_bipedalwalker-v2_2021}
\citation{noauthor_bipedalwalkerhardcore-v2_2021}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Problem Statement: Bipedal Walker Robot Control}{2}{section.1.1}\protected@file@percent }
\newlabel{sec:problem_statement}{{1.1}{2}{Problem Statement: Bipedal Walker Robot Control}{section.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}OpenAI Gym and Bipedal-Walker Environment}{2}{subsection.1.1.1}\protected@file@percent }
\newlabel{gym_bipedal}{{1.1.1}{2}{OpenAI Gym and Bipedal-Walker Environment}{subsection.1.1.1}{}}
\citation{paszke_pytorch_2019}
\citation{collobert_torch7_2011}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bipedal_walker_classic}{{1.1a}{3}{Bipedal-Walker-v3 Snapshot\relax }{figure.caption.9}{}}
\newlabel{sub@fig:bipedal_walker_classic}{{a}{3}{Bipedal-Walker-v3 Snapshot\relax }{figure.caption.9}{}}
\newlabel{fig:bipedal_walker_hardcore}{{1.1b}{3}{Bipedal-Walker-Hardcore-v3 Snapshot\relax }{figure.caption.9}{}}
\newlabel{sub@fig:bipedal_walker_hardcore}{{b}{3}{Bipedal-Walker-Hardcore-v3 Snapshot\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Bipedal Walkers Snapshots\relax }}{3}{figure.caption.9}\protected@file@percent }
\newlabel{fig:bipedal_walkers}{{1.1}{3}{Bipedal Walkers Snapshots\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Deep Learning Library: PyTorch}{3}{subsection.1.1.2}\protected@file@percent }
\newlabel{dl_pytorch}{{1.1.2}{3}{Deep Learning Library: PyTorch}{subsection.1.1.2}{}}
\citation{pan_virtual_2017}
\citation{shalev-shwartz_safe_2016}
\citation{sallab_deep_2017}
\citation{wang_deep_2019}
\citation{kopsa_reinforcement_2018}
\citation{abbeel_application_2006}
\citation{santos_experimental_2012}
\citation{rastogi_deep_2017}
\citation{kumar_bipedal_2018}
\citation{song_recurrent_2018}
\citation{heess_memory-based_2015}
\citation{fris_landing_2020}
\citation{fu_when_2020}
\citation{upadhyay_transformer_2019}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Proposed Methods and Contribution}{4}{section.1.2}\protected@file@percent }
\newlabel{sec:proposedmethods}{{1.2}{4}{Proposed Methods and Contribution}{section.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Related Work}{4}{section.1.3}\protected@file@percent }
\newlabel{sec:relatedwork}{{1.3}{4}{Related Work}{section.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Outline of the Thesis}{5}{section.1.4}\protected@file@percent }
\newlabel{sec:outline}{{1.4}{5}{Outline of the Thesis}{section.1.4}{}}
\citation{mitchell_machine_1997}
\citation{russell_artificial_nodate}
\citation{russell_artificial_nodate}
\citation{sutton_reinforcement_1998}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}\MakeUppercase  {REINFORCEMENT LEARNING}}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{chap:rl_chap}{{2}{7}{REINFORCEMENT LEARNING}{chapter.2}{}}
\citation{dulac-arnold_challenges_2019}
\citation{sutton_reinforcement_1998}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Reinforcement Learning and Optimal Control}{8}{section.2.1}\protected@file@percent }
\newlabel{sec:rl_and_control}{{2.1}{8}{Reinforcement Learning and Optimal Control}{section.2.1}{}}
\citation{sutton_reinforcement_1998}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Challenges}{9}{section.2.2}\protected@file@percent }
\newlabel{sec:chal}{{2.2}{9}{Challenges}{section.2.2}{}}
\citation{francois-lavet_introduction_2018}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Sequential Decision Making}{10}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Markov Decision Process}{10}{section.2.4}\protected@file@percent }
\newlabel{sec:mdp}{{2.4}{10}{Markov Decision Process}{section.2.4}{}}
\citation{francois-lavet_introduction_2018}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Partially Observed Markov Decision Process}{11}{section.2.5}\protected@file@percent }
\newlabel{sec:pomdp}{{2.5}{11}{Partially Observed Markov Decision Process}{section.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Policy}{11}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Return, Value Functions and Policy Learning}{11}{section.2.7}\protected@file@percent }
\citation{bellman_dynamic_2003}
\newlabel{eqn:policy_stochastic_q}{{2.7}{12}{Return, Value Functions and Policy Learning}{equation.2.7.7}{}}
\newlabel{eqn:policy_deterministic_q}{{2.8}{12}{Return, Value Functions and Policy Learning}{equation.2.7.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Bellman Equation}{12}{section.2.8}\protected@file@percent }
\newlabel{eqn:bellman_v}{{2.9}{12}{Bellman Equation}{equation.2.8.9}{}}
\newlabel{eqn:bellman_q}{{2.10}{12}{Bellman Equation}{equation.2.8.10}{}}
\citation{watkins_technical_1992}
\citation{mnih_human-level_2015}
\citation{mnih_playing_2013}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Model Free Reinforcement Learning}{13}{section.2.9}\protected@file@percent }
\newlabel{sec:mf_rl}{{2.9}{13}{Model Free Reinforcement Learning}{section.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.1}Q Learning}{13}{subsection.2.9.1}\protected@file@percent }
\newlabel{eqn:q_target}{{2.11}{13}{Q Learning}{equation.2.9.11}{}}
\newlabel{eqn:q_loss}{{2.12}{13}{Q Learning}{equation.2.9.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.1.1}Deep Q Learning}{14}{subsubsection.2.9.1.1}\protected@file@percent }
\newlabel{eqn:dqn_ntarget}{{2.13}{14}{Deep Q Learning}{equation.2.9.13}{}}
\newlabel{eqn:dqn_loss}{{2.14}{14}{Deep Q Learning}{equation.2.9.14}{}}
\newlabel{eqn:egreedy_policy}{{2.15}{14}{Deep Q Learning}{equation.2.9.15}{}}
\citation{van_hasselt_deep_2015}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Deep Q Learning with Experience Replay\relax }}{15}{algocf.1}\protected@file@percent }
\newlabel{alg:dqn}{{1}{15}{Deep Q Learning}{algocf.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.1.2}Double Deep Q Learning}{15}{subsubsection.2.9.1.2}\protected@file@percent }
\newlabel{eqn:ddqn_ntarget}{{2.16}{15}{Double Deep Q Learning}{equation.2.9.16}{}}
\citation{silver_deterministic_2014}
\citation{lillicrap_continuous_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.2}Deterministic Actor Critic Learning}{16}{subsection.2.9.2}\protected@file@percent }
\newlabel{eqn:dpg_value_maximization}{{2.17}{16}{Deterministic Actor Critic Learning}{equation.2.9.17}{}}
\newlabel{eqn:dpg_target}{{2.18}{16}{Deterministic Actor Critic Learning}{equation.2.9.18}{}}
\newlabel{eqn:dpq_loss}{{2.19}{16}{Deterministic Actor Critic Learning}{equation.2.9.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.2.1}Deep Deterministic Policy Gradient}{16}{subsubsection.2.9.2.1}\protected@file@percent }
\citation{lillicrap_continuous_2019}
\citation{uhlenbeck_theory_1930}
\newlabel{eqn:target_update}{{2.20}{17}{Deep Deterministic Policy Gradient}{equation.2.9.20}{}}
\newlabel{eqn:ddpg_value_maximization}{{2.21}{17}{Deep Deterministic Policy Gradient}{equation.2.9.21}{}}
\newlabel{eqn:ddpg_target}{{2.22}{17}{Deep Deterministic Policy Gradient}{equation.2.9.22}{}}
\newlabel{eqn:ddpg_loss}{{2.23}{17}{Deep Deterministic Policy Gradient}{equation.2.9.23}{}}
\citation{fujimoto_addressing_2018}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Deep Deterministic Policy Gradient\relax }}{18}{algocf.2}\protected@file@percent }
\newlabel{alg:ddpg}{{2}{18}{Deep Deterministic Policy Gradient}{algocf.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.2.2}Twin Delayed Deep Deterministic Policy Gradient}{18}{subsubsection.2.9.2.2}\protected@file@percent }
\newlabel{eqn:td3_target_action}{{2.24}{19}{Twin Delayed Deep Deterministic Policy Gradient}{equation.2.9.24}{}}
\newlabel{eqn:td3_target}{{2.25}{19}{Twin Delayed Deep Deterministic Policy Gradient}{equation.2.9.25}{}}
\newlabel{eqn:td3_value_maximization}{{2.26}{19}{Twin Delayed Deep Deterministic Policy Gradient}{equation.2.9.26}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Twin Delayed Deep Deterministic Policy Gradient\relax }}{20}{algocf.3}\protected@file@percent }
\newlabel{alg:td3}{{3}{20}{Twin Delayed Deep Deterministic Policy Gradient}{algocf.3}{}}
\citation{mcculloch_logical_1943}
\citation{rosenblatt_perceptron_1958}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}\MakeUppercase  {NEURAL NETWORKS AND DEEP LEARNING}}{21}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{chap:dnns}{{3}{21}{NEURAL NETWORKS AND DEEP LEARNING}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Backpropagation}{21}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Building Units}{22}{section.3.2}\protected@file@percent }
\newlabel{sec:building_units}{{3.2}{22}{Building Units}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Perceptron}{22}{subsection.3.2.1}\protected@file@percent }
\newlabel{eqn:perceptron1}{{3.1}{22}{Perceptron}{equation.3.2.1}{}}
\newlabel{eqn:stepfun}{{3.2}{22}{Perceptron}{equation.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Activation Functions}{22}{subsection.3.2.2}\protected@file@percent }
\citation{glorot_deep_2011}
\citation{hendrycks_gaussian_2020}
\newlabel{fig:relu_gelu}{{3.1a}{23}{ReLU and GELU functions\relax }{figure.caption.10}{}}
\newlabel{sub@fig:relu_gelu}{{a}{23}{ReLU and GELU functions\relax }{figure.caption.10}{}}
\newlabel{fig:sigmoid_tanh}{{3.1b}{23}{Sigmoid and Tanh functions\relax }{figure.caption.10}{}}
\newlabel{sub@fig:sigmoid_tanh}{{b}{23}{Sigmoid and Tanh functions\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Activation Functions\relax }}{23}{figure.caption.10}\protected@file@percent }
\newlabel{fig:activation_functions}{{3.1}{23}{Activation Functions\relax }{figure.caption.10}{}}
\newlabel{eqn:sigmoid_fcn}{{3.3}{23}{Activation Functions}{equation.3.2.3}{}}
\newlabel{eqn:tanh_fcn}{{3.4}{23}{Activation Functions}{equation.3.2.4}{}}
\newlabel{eqn:relu_fcn}{{3.5}{23}{Activation Functions}{equation.3.2.5}{}}
\newlabel{eqn:gelu_fcn}{{3.6}{23}{Activation Functions}{equation.3.2.6}{}}
\citation{rumelhart_learning_1986}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Neural Network Types}{24}{section.3.3}\protected@file@percent }
\newlabel{sec:nnet_types}{{3.3}{24}{Neural Network Types}{section.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Feed Forward Neural Networks (Multilayer Perceptron)}{24}{subsection.3.3.1}\protected@file@percent }
\newlabel{eqn:mlpact}{{3.7}{24}{Feed Forward Neural Networks (Multilayer Perceptron)}{equation.3.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Recurrent Neural Networks}{24}{subsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Recurrent Layer (left) and Feed Forward Layer (right) illustration.\relax }}{25}{figure.caption.11}\protected@file@percent }
\newlabel{fig:rnn_vs_ffnn}{{3.2}{25}{Recurrent Layer (left) and Feed Forward Layer (right) illustration.\relax }{figure.caption.11}{}}
\newlabel{eqn:rnnact}{{3.8}{25}{Recurrent Neural Networks}{equation.3.3.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.1}Long Term Dependence Problem of Vanilla RNNs}{25}{subsubsection.3.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.2}Long Short Term Memory}{25}{subsubsection.3.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces LSTM Cell.\relax }}{26}{figure.caption.12}\protected@file@percent }
\newlabel{fig:lstm_cell}{{3.3}{26}{LSTM Cell.\relax }{figure.caption.12}{}}
\newlabel{eqn:lstm_forget}{{3.9}{26}{Long Short Term Memory}{equation.3.3.9}{}}
\newlabel{eqn:lstm_inp}{{3.10}{26}{Long Short Term Memory}{equation.3.3.10}{}}
\newlabel{eqn:lstm_cellstcand}{{3.11}{26}{Long Short Term Memory}{equation.3.3.11}{}}
\newlabel{eqn:lstm_cellstupt}{{3.12}{26}{Long Short Term Memory}{equation.3.3.12}{}}
\newlabel{eqn:lstm_out}{{3.13}{26}{Long Short Term Memory}{equation.3.3.13}{}}
\citation{vaswani_attention_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Attention Mechanism}{27}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3.1}Transformer}{27}{subsubsection.3.3.3.1}\protected@file@percent }
\newlabel{eq:layernorm_statistics}{{3.19}{29}{Transformer}{equation.3.3.19}{}}
\newlabel{eqn:layernorm}{{3.20}{29}{Transformer}{equation.3.3.20}{}}
\citation{xiong_layer_2020}
\citation{parisotto_stabilizing_2019}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3.2}Pre-Layer Normalized Transformer}{30}{subsubsection.3.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces (a) Post-LN Transformer layer, (b) Pre-LN Transformer layer.\relax }}{31}{figure.caption.13}\protected@file@percent }
\newlabel{fig:post_pre_trsf}{{3.4}{31}{(a) Post-LN Transformer layer, (b) Pre-LN Transformer layer.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}\MakeUppercase  {BIPEDAL WALKING BY TWIN DELAYED DEEP DETERMINISTIC POLICY GRADIENTS}}{33}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{chap:exp_setup}{{4}{33}{BIPEDAL WALKING BY TWIN DELAYED DEEP DETERMINISTIC POLICY GRADIENTS}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Details of the Environment}{33}{section.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Observation Space of Bipedal Walker\relax }}{33}{table.caption.14}\protected@file@percent }
\newlabel{table:bpw_obs_space}{{4.1}{33}{Observation Space of Bipedal Walker\relax }{table.caption.14}{}}
\citation{dulac-arnold_challenges_2019}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Action Space of Bipedal Walker\relax }}{34}{table.caption.15}\protected@file@percent }
\newlabel{table:bpw_act_space}{{4.2}{34}{Action Space of Bipedal Walker\relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Partial Observability}{34}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Modifications on Original Envrionment}{34}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Proposed Neural Networks}{34}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Feed Forward Network}{35}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Long Short Term Memory}{35}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Transformer (Pre-layer Normalized)}{35}{subsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}RL Method and hyperparameters}{35}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Results}{35}{section.4.5}\protected@file@percent }
\bibdata{myBiblio}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}\MakeUppercase  {CONCLUSION AND FUTURE WORK}}{37}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{5}{37}{CONCLUSION AND FUTURE WORK}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Conclusion}{37}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Future Work}{37}{section.5.2}\protected@file@percent }
\bibcite{noauthor_bipedalwalker-v2_2021}{1}
\bibcite{noauthor_bipedalwalkerhardcore-v2_2021}{2}
\bibcite{abbeel_application_2006}{3}
\bibcite{bellman_dynamic_2003}{4}
\bibcite{brockman_openai_2016}{5}
\bibcite{collobert_torch7_2011}{6}
\bibcite{dulac-arnold_challenges_2019}{7}
\bibcite{francois-lavet_introduction_2018}{8}
\bibcite{fris_landing_2020}{9}
\bibcite{fu_when_2020}{10}
\bibcite{fujimoto_addressing_2018}{11}
\bibcite{glorot_deep_2011}{12}
\bibcite{heess_memory-based_2015}{13}
\@writefile{toc}{\contentsline {leads}{\numberline {}\uppercase {REFERENCES}}{39}{chapter*.16}\protected@file@percent }
\bibcite{hendrycks_gaussian_2020}{14}
\bibcite{kopsa_reinforcement_2018}{15}
\bibcite{kumar_bipedal_2018}{16}
\bibcite{lillicrap_continuous_2019}{17}
\bibcite{mcculloch_logical_1943}{18}
\bibcite{mitchell_machine_1997}{19}
\bibcite{mnih_playing_2013}{20}
\bibcite{mnih_human-level_2015}{21}
\bibcite{pan_virtual_2017}{22}
\bibcite{parisotto_stabilizing_2019}{23}
\bibcite{paszke_pytorch_2019}{24}
\bibcite{rastogi_deep_2017}{25}
\bibcite{rosenblatt_perceptron_1958}{26}
\bibcite{rumelhart_learning_1986}{27}
\bibcite{russell_artificial_nodate}{28}
\bibcite{sallab_deep_2017}{29}
\bibcite{santos_experimental_2012}{30}
\bibcite{shalev-shwartz_safe_2016}{31}
\bibcite{silver_deterministic_2014}{32}
\bibcite{song_recurrent_2018}{33}
\bibcite{sutton_reinforcement_1998}{34}
\bibcite{uhlenbeck_theory_1930}{35}
\bibcite{upadhyay_transformer_2019}{36}
\bibcite{van_hasselt_deep_2015}{37}
\bibcite{vaswani_attention_2017}{38}
\bibcite{wang_deep_2019}{39}
\bibcite{watkins_technical_1992}{40}
\bibcite{xiong_layer_2020}{41}
\bibstyle{iamBiblioStyle}
\@writefile{toc}{\contentsline {nodots}{\numberline {}APPENDICES}{42}{chapter*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}\MakeUppercase  {Proof of Some Theorem}}{43}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{app:somethms}{{A}{43}{Proof of Some Theorem}{appendix.A}{}}
\newlabel{`@lastpage'}{{A}{43}{Proof of Some Theorem}{listing.A.1}{}}
\@writefile{lol}{\contentsline {listing}{\numberline {A.1}{\ignorespaces The \texttt  {lintest} function in a floating ``listing'' environment.\relax }}{44}{listing.A.1}\protected@file@percent }
\newlabel{mfile:linetest-3}{{A.1}{44}{The \texttt {lintest} function in a floating ``listing'' environment.\relax }{listing.A.1}{}}
