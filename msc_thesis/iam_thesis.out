\BOOKMARK [0][-]{chapter*.1}{ABSTRACT}{}% 1
\BOOKMARK [0][-]{chapter*.2}{\326Z}{}% 2
\BOOKMARK [0][-]{chapter*.3}{ACKNOWLEDGMENTS}{}% 3
\BOOKMARK [0][-]{chapter*.4}{TABLE OF CONTENTS}{}% 4
\BOOKMARK [0][-]{chapter*.5}{LIST OF TABLES}{}% 5
\BOOKMARK [0][-]{chapter*.6}{LIST OF FIGURES}{}% 6
\BOOKMARK [0][-]{chapter*.7}{LIST OF ABBREVIATIONS}{}% 7
\BOOKMARK [0][-]{chapter.1}{INTRODUCTION}{}% 8
\BOOKMARK [1][-]{section.1.1}{Problem Statement: Bipedal Walker Robot Control}{chapter.1}% 9
\BOOKMARK [2][-]{subsection.1.1.1}{OpenAI Gym and Bipedal-Walker Environment}{section.1.1}% 10
\BOOKMARK [2][-]{subsection.1.1.2}{Deep Learning Library: PyTorch}{section.1.1}% 11
\BOOKMARK [1][-]{section.1.2}{Proposed Methods and Contribution}{chapter.1}% 12
\BOOKMARK [1][-]{section.1.3}{Related Work}{chapter.1}% 13
\BOOKMARK [1][-]{section.1.4}{Outline of the Thesis}{chapter.1}% 14
\BOOKMARK [0][-]{chapter.2}{REINFORCEMENT LEARNING}{}% 15
\BOOKMARK [1][-]{section.2.1}{Reinforcement Learning and Optimal Control}{chapter.2}% 16
\BOOKMARK [1][-]{section.2.2}{Challenges}{chapter.2}% 17
\BOOKMARK [1][-]{section.2.3}{Markov Decision Process}{chapter.2}% 18
\BOOKMARK [2][-]{subsection.2.3.1}{Value Functions}{section.2.3}% 19
\BOOKMARK [3][-]{subsubsection.2.3.1.1}{State Value Function}{subsection.2.3.1}% 20
\BOOKMARK [3][-]{subsubsection.2.3.1.2}{State-Action Value Function}{subsection.2.3.1}% 21
\BOOKMARK [1][-]{section.2.4}{Model Based Reinforcement Learning}{chapter.2}% 22
\BOOKMARK [1][-]{section.2.5}{Model Free Reinforcement Learning}{chapter.2}% 23
\BOOKMARK [2][-]{subsection.2.5.1}{Temporal Difference}{section.2.5}% 24
\BOOKMARK [2][-]{subsection.2.5.2}{Q-Learning}{section.2.5}% 25
\BOOKMARK [0][-]{chapter.3}{NEURAL NETWORKS AND DEEP LEARNING}{}% 26
\BOOKMARK [1][-]{section.3.1}{Neural Networks}{chapter.3}% 27
\BOOKMARK [1][-]{section.3.2}{Numerical Optimization}{chapter.3}% 28
\BOOKMARK [1][-]{section.3.3}{Neural Network Types}{chapter.3}% 29
\BOOKMARK [2][-]{subsection.3.3.1}{Perceptron}{section.3.3}% 30
\BOOKMARK [2][-]{subsection.3.3.2}{Feed Forward Neural Networks \(Multilayer Perceptron\)}{section.3.3}% 31
\BOOKMARK [2][-]{subsection.3.3.3}{Recurrent Neural Networks}{section.3.3}% 32
\BOOKMARK [3][-]{subsubsection.3.3.3.1}{Long Term Dependence Problem of Vanilla RNNs}{subsection.3.3.3}% 33
\BOOKMARK [3][-]{subsubsection.3.3.3.2}{Long Short Term Memory}{subsection.3.3.3}% 34
\BOOKMARK [2][-]{subsection.3.3.4}{Attention Mechanism}{section.3.3}% 35
\BOOKMARK [3][-]{subsubsection.3.3.4.1}{Transformer}{subsection.3.3.4}% 36
\BOOKMARK [3][-]{subsubsection.3.3.4.2}{Pre-Layer Normalized Transformer}{subsection.3.3.4}% 37
\BOOKMARK [0][-]{chapter.4}{DEEP REINFORCEMENT LEARNING}{}% 38
\BOOKMARK [1][-]{section.4.1}{Deep Reinforcement Learning Algorithms on Continious Action Space}{chapter.4}% 39
\BOOKMARK [2][-]{subsection.4.1.1}{Deep Q-Learning}{section.4.1}% 40
\BOOKMARK [2][-]{subsection.4.1.2}{Double Deep Q-Learning}{section.4.1}% 41
\BOOKMARK [2][-]{subsection.4.1.3}{Deep Deterministic Policy Gradient}{section.4.1}% 42
\BOOKMARK [2][-]{subsection.4.1.4}{Twin Delayed Deep Deterministic Policy Gradient}{section.4.1}% 43
\BOOKMARK [0][-]{chapter.5}{BIPEDAL WALKING BY TWIN DELAYED DEEP DETERMINISTIC POLICY GRADIENTS}{}% 44
\BOOKMARK [1][-]{section.5.1}{Details of the Environment}{chapter.5}% 45
\BOOKMARK [2][-]{subsection.5.1.1}{Partial Observability}{section.5.1}% 46
\BOOKMARK [1][-]{section.5.2}{RL Method and hyperparameters}{chapter.5}% 47
\BOOKMARK [1][-]{section.5.3}{Proposed Neural Networks}{chapter.5}% 48
\BOOKMARK [2][-]{subsection.5.3.1}{Feed Forward Network}{section.5.3}% 49
\BOOKMARK [2][-]{subsection.5.3.2}{Long Short Term Memory}{section.5.3}% 50
\BOOKMARK [2][-]{subsection.5.3.3}{Transformer \(Pre-layer Normalized\)}{section.5.3}% 51
\BOOKMARK [1][-]{section.5.4}{Results}{chapter.5}% 52
\BOOKMARK [0][-]{chapter.6}{CONCLUSION AND FUTURE WORK}{}% 53
\BOOKMARK [1][-]{section.6.1}{Conclusion}{chapter.6}% 54
\BOOKMARK [1][-]{section.6.2}{Future Work}{chapter.6}% 55
\BOOKMARK [0][-]{chapter*.12}{REFERENCES}{}% 56
\BOOKMARK [0][-]{chapter*.12}{APPENDICES}{}% 57
\BOOKMARK [0][-]{appendix.A}{Proof of Some Theorem}{}% 58
