\babel@toc {english}{}
\babel@toc {english}{}
\contentsline {leads}{\numberline {}ABSTRACT}{vii}{chapter*.1}%
\babel@toc {english}{}
\babel@toc {turkish}{}
\contentsline {leads}{\numberline {}\"OZ}{ix}{chapter*.2}%
\babel@toc {english}{}
\contentsline {leads}{\numberline {}ACKNOWLEDGMENTS}{xi}{chapter*.3}%
\contentsline {leads}{\numberline {}TABLE OF CONTENTS}{xiii}{chapter*.4}%
\contentsline {leads}{\numberline {}LIST OF TABLES}{xvii}{chapter*.5}%
\contentsline {leads}{\numberline {}LIST OF FIGURES}{xviii}{chapter*.6}%
\contentsline {leads}{\numberline {}LIST OF ALGORITHMS}{xix}{chapter*.7}%
\contentsline {leads}{\numberline {}LIST OF ABBREVIATIONS}{xx}{chapter*.8}%
\numberline {}CHAPTERS
\babel@toc {turkish}{}
\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}\MakeUppercase {INTRODUCTION}}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Problem Statement: Bipedal Walker Robot Control}{2}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}OpenAI Gym and Bipedal-Walker Environment}{2}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}Deep Learning Library: PyTorch}{3}{subsection.1.1.2}%
\contentsline {section}{\numberline {1.2}Proposed Methods and Contribution}{4}{section.1.2}%
\contentsline {section}{\numberline {1.3}Related Work}{4}{section.1.3}%
\contentsline {section}{\numberline {1.4}Outline of the Thesis}{5}{section.1.4}%
\contentsline {chapter}{\numberline {2}\MakeUppercase {REINFORCEMENT LEARNING}}{7}{chapter.2}%
\contentsline {section}{\numberline {2.1}Reinforcement Learning and Optimal Control}{8}{section.2.1}%
\contentsline {section}{\numberline {2.2}Challenges}{9}{section.2.2}%
\contentsline {section}{\numberline {2.3}Sequential Decision Making}{10}{section.2.3}%
\contentsline {section}{\numberline {2.4}Markov Decision Process}{10}{section.2.4}%
\contentsline {section}{\numberline {2.5}Partially Observed Markov Decision Process}{11}{section.2.5}%
\contentsline {section}{\numberline {2.6}Policy}{11}{section.2.6}%
\contentsline {section}{\numberline {2.7}Return, Value Functions and Policy Learning}{11}{section.2.7}%
\contentsline {section}{\numberline {2.8}Bellman Equation}{12}{section.2.8}%
\contentsline {section}{\numberline {2.9}Model Free Reinforcement Learning}{13}{section.2.9}%
\contentsline {subsection}{\numberline {2.9.1}Q Learning}{13}{subsection.2.9.1}%
\contentsline {subsubsection}{\numberline {2.9.1.1}Deep Q Learning}{14}{subsubsection.2.9.1.1}%
\contentsline {subsubsection}{\numberline {2.9.1.2}Double Deep Q Learning}{15}{subsubsection.2.9.1.2}%
\contentsline {subsection}{\numberline {2.9.2}Deterministic Actor Critic Learning}{16}{subsection.2.9.2}%
\contentsline {subsubsection}{\numberline {2.9.2.1}Deep Deterministic Policy Gradient}{16}{subsubsection.2.9.2.1}%
\contentsline {subsubsection}{\numberline {2.9.2.2}Twin Delayed Deep Deterministic Policy Gradient}{18}{subsubsection.2.9.2.2}%
\contentsline {chapter}{\numberline {3}\MakeUppercase {NEURAL NETWORKS AND DEEP LEARNING}}{21}{chapter.3}%
\contentsline {section}{\numberline {3.1}Backpropagation and Numerical Optimization}{21}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Stochastic Gradient Descent Optimization}{22}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Adam Optimization}{22}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Building Units}{23}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Perceptron}{23}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Activation Functions}{23}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Layer Normalization}{25}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Neural Network Types}{25}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Feed Forward Neural Networks (Multilayer Perceptron)}{25}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Recurrent Neural Networks}{26}{subsection.3.3.2}%
\contentsline {subsubsection}{\numberline {3.3.2.1}Long Term Dependence Problem of Vanilla RNNs}{27}{subsubsection.3.3.2.1}%
\contentsline {subsubsection}{\numberline {3.3.2.2}Long Short Term Memory}{27}{subsubsection.3.3.2.2}%
\contentsline {subsection}{\numberline {3.3.3}Attention Mechanism}{28}{subsection.3.3.3}%
\contentsline {subsubsection}{\numberline {3.3.3.1}Transformer}{29}{subsubsection.3.3.3.1}%
\contentsline {subsubsection}{\numberline {3.3.3.2}Pre-Layer Normalized Transformer}{31}{subsubsection.3.3.3.2}%
\contentsline {chapter}{\numberline {4}\MakeUppercase {BIPEDAL WALKING BY TWIN DELAYED DEEP DETERMINISTIC POLICY GRADIENTS}}{33}{chapter.4}%
\contentsline {section}{\numberline {4.1}Details of the Environment}{33}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Partial Observability}{35}{subsection.4.1.1}%
\contentsline {section}{\numberline {4.2}Proposed Neural Networks}{35}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Feed Forward Network with residual connection}{35}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Long Short Term Memory}{36}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}Transformer (Pre-layer Normalized)}{36}{subsection.4.2.3}%
\contentsline {section}{\numberline {4.3}RL Method and hyperparameters}{36}{section.4.3}%
\contentsline {section}{\numberline {4.4}Results}{37}{section.4.4}%
\contentsline {chapter}{\numberline {5}\MakeUppercase {CONCLUSION AND FUTURE WORK}}{39}{chapter.5}%
\contentsline {section}{\numberline {5.1}Conclusion}{39}{section.5.1}%
\contentsline {section}{\numberline {5.2}Future Work}{39}{section.5.2}%
\contentsline {leads}{\numberline {}\uppercase {REFERENCES}}{41}{chapter*.17}%
\contentsline {nodots}{\numberline {}APPENDICES}{44}{chapter*.17}%
\contentsline {chapter}{\numberline {A}\MakeUppercase {Proof of Some Theorem}}{45}{appendix.A}%
