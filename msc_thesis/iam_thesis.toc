\babel@toc {english}{}
\babel@toc {english}{}
\contentsline {leads}{\numberline {}ABSTRACT}{vii}{chapter*.1}%
\babel@toc {english}{}
\babel@toc {turkish}{}
\contentsline {leads}{\numberline {}\"OZ}{ix}{chapter*.2}%
\babel@toc {english}{}
\contentsline {leads}{\numberline {}ACKNOWLEDGMENTS}{xi}{chapter*.3}%
\contentsline {leads}{\numberline {}TABLE OF CONTENTS}{xiii}{chapter*.4}%
\contentsline {leads}{\numberline {}LIST OF TABLES}{xvii}{chapter*.5}%
\contentsline {leads}{\numberline {}LIST OF FIGURES}{xviii}{chapter*.6}%
\contentsline {leads}{\numberline {}LIST OF ALGORITHMS}{xix}{chapter*.7}%
\contentsline {leads}{\numberline {}LIST OF ABBREVIATIONS}{xx}{chapter*.8}%
\numberline {}CHAPTERS
\babel@toc {turkish}{}
\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}\MakeUppercase {INTRODUCTION}}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Problem Statement: Bipedal Walker Robot Control}{2}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}OpenAI Gym and Bipedal-Walker Environment}{2}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}Deep Learning Library: PyTorch}{3}{subsection.1.1.2}%
\contentsline {section}{\numberline {1.2}Proposed Methods and Contribution}{4}{section.1.2}%
\contentsline {section}{\numberline {1.3}Related Work}{4}{section.1.3}%
\contentsline {section}{\numberline {1.4}Outline of the Thesis}{5}{section.1.4}%
\contentsline {chapter}{\numberline {2}\MakeUppercase {REINFORCEMENT LEARNING}}{7}{chapter.2}%
\contentsline {section}{\numberline {2.1}Reinforcement Learning and Optimal Control}{8}{section.2.1}%
\contentsline {section}{\numberline {2.2}Challenges}{9}{section.2.2}%
\contentsline {section}{\numberline {2.3}Sequential Decision Making}{10}{section.2.3}%
\contentsline {section}{\numberline {2.4}Markov Decision Process}{10}{section.2.4}%
\contentsline {section}{\numberline {2.5}Partially Observed Markov Decision Process}{11}{section.2.5}%
\contentsline {section}{\numberline {2.6}Policy}{11}{section.2.6}%
\contentsline {section}{\numberline {2.7}Return, Value Functions and Policy Learning}{11}{section.2.7}%
\contentsline {section}{\numberline {2.8}Bellman Equation}{12}{section.2.8}%
\contentsline {section}{\numberline {2.9}Model Free Reinforcement Learning}{13}{section.2.9}%
\contentsline {subsection}{\numberline {2.9.1}Q Learning}{13}{subsection.2.9.1}%
\contentsline {subsubsection}{\numberline {2.9.1.1}Deep Q Learning}{14}{subsubsection.2.9.1.1}%
\contentsline {subsubsection}{\numberline {2.9.1.2}Double Deep Q Learning}{15}{subsubsection.2.9.1.2}%
\contentsline {subsection}{\numberline {2.9.2}Deterministic Actor Critic Learning}{15}{subsection.2.9.2}%
\contentsline {subsubsection}{\numberline {2.9.2.1}Deep Deterministic Policy Gradient}{16}{subsubsection.2.9.2.1}%
\contentsline {subsubsection}{\numberline {2.9.2.2}Twin Delayed Deep Deterministic Policy Gradient}{17}{subsubsection.2.9.2.2}%
\contentsline {chapter}{\numberline {3}\MakeUppercase {NEURAL NETWORKS AND DEEP LEARNING}}{19}{chapter.3}%
\contentsline {section}{\numberline {3.1}Neural Networks}{19}{section.3.1}%
\contentsline {section}{\numberline {3.2}Backpropagation}{20}{section.3.2}%
\contentsline {section}{\numberline {3.3}Neural Network Types}{20}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Perceptron}{20}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Feed Forward Neural Networks (Multilayer Perceptron)}{20}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Recurrent Neural Networks}{21}{subsection.3.3.3}%
\contentsline {subsubsection}{\numberline {3.3.3.1}Long Term Dependence Problem of Vanilla RNNs}{22}{subsubsection.3.3.3.1}%
\contentsline {subsubsection}{\numberline {3.3.3.2}Long Short Term Memory}{22}{subsubsection.3.3.3.2}%
\contentsline {subsection}{\numberline {3.3.4}Attention Mechanism}{24}{subsection.3.3.4}%
\contentsline {subsubsection}{\numberline {3.3.4.1}Transformer}{24}{subsubsection.3.3.4.1}%
\contentsline {subsubsection}{\numberline {3.3.4.2}Pre-Layer Normalized Transformer}{27}{subsubsection.3.3.4.2}%
\contentsline {chapter}{\numberline {4}\MakeUppercase {BIPEDAL WALKING BY TWIN DELAYED DEEP DETERMINISTIC POLICY GRADIENTS}}{29}{chapter.4}%
\contentsline {section}{\numberline {4.1}Details of the Environment}{29}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Partial Observability}{30}{subsection.4.1.1}%
\contentsline {section}{\numberline {4.2}Proposed Neural Networks}{30}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Feed Forward Network}{31}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Long Short Term Memory}{31}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}Transformer (Pre-layer Normalized)}{31}{subsection.4.2.3}%
\contentsline {section}{\numberline {4.3}RL Method and hyperparameters}{31}{section.4.3}%
\contentsline {section}{\numberline {4.4}Results}{31}{section.4.4}%
\contentsline {chapter}{\numberline {5}\MakeUppercase {CONCLUSION AND FUTURE WORK}}{33}{chapter.5}%
\contentsline {section}{\numberline {5.1}Conclusion}{33}{section.5.1}%
\contentsline {section}{\numberline {5.2}Future Work}{33}{section.5.2}%
\contentsline {leads}{\numberline {}\uppercase {REFERENCES}}{35}{chapter*.15}%
\contentsline {nodots}{\numberline {}APPENDICES}{37}{chapter*.15}%
\contentsline {chapter}{\numberline {A}\MakeUppercase {Proof of Some Theorem}}{39}{appendix.A}%
