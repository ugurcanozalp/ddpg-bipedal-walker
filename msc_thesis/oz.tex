google translate şimdilik -> Mekanik kontrol üzerine Derin Takviyeli Öğrenme (DRL) yöntemleri birçok ortamda başarılıdır ve bazı karmaşık durumlarda geleneksel optimal ve uyarlanabilir kontrol yöntemleri yerine kullanılır. Ancak, DRL algoritmalarının hala zorlukları vardır. Birincisi, kısmen gözlemlenebilir ortamlarda kontroldür. Bir temsilci çevre hakkında yeterince bilgilendirilmediğinde, geçmiş gözlemlerden bilgileri kurtarmalıdır. Bu tezde, Bipedal Walker (OpenAI GYM) ortamının DRL kontrolü, sürekli aktör-eleştirmen algoritması Twin Delayed Deep Determinstic Policy Gradient (TD3) ile DRL tarafından incelenmiştir. Çevre kısmen gözlemlenebilir olduğundan, birkaç sinir mimarisi uygulanmaktadır Birincisi, gözlemlenebilir ortam varsayımı altında ileri beslemeli sinir ağı iken, ikincisi ve üçüncüsü, kurtarmak için girdi olarak son 16 zaman adımı gözlemini kullanan Transformer ve Uzun Kısa Süreli Bellek (LSTM) gizli durum, çünkü çevrenin kısmen gözlemlenebilir olduğu varsayılır.