Mekanik kontrol üzerine Derin Pekiştirmeli Öğrenme yöntemleri birçok ortamda başarıyla uygulanmış ve bazı karmaşık problemler için geleneksel optimal ve uyarlanabilir kontrol yöntemleri yerine kullanılmıştır.
Bununla birlikte, Derin Pekiştirmeli Öğrenme algoritmalarının hala bazı zorlukları vardır.
Bunlardan bir tanesi, kısmen gözlemlenebilir ortamlarda özneyi kontrol etmektir.
Bir özne ortam hakkında yeterince bilgilendirilmediğinde, geçmiş gözlemleri anlık gözlemlere ek olarak kullanmalıdır.
Bu tezde kısmen gözlemlenebilir olan Bipedal Walker Hardcore (OpenAI GYM) ortamında yürüme kontrolü,
iki sürekli aktör-eleştirmen pekiştirmeli öğrenme algoritması tarafından incelenmiştir; İkiz Gecikmeli Derin Belirleyici Poliçe Gradyanı (Twin Delayed Deep Determinstic Policy Gradient) ve Hafif Aktör Eleştirmen (Soft Actor-Critic).
Birkaç sinir mimarisi uygulanmıştır.
Birincisi, gözlemlenebilir ortam varsayımına göre Artık Bağlantılı İleri Beslemeli Sinir Ağı iken
ikincisi ve üçüncüsü, ortamın kısmen gözlemlenebilir olduğu varsayıldığından, gizli durumu kurtarmak için girdi olarak gözlem geçmişini kullanan Uzun Kısa Süreli Bellek (LSTM) ve Transformatördür (Transformer).